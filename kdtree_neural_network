import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from keras.models import Sequential
from keras.layers import Dense

train_data = pd.read_csv("mnist_train.csv", header=None)
test_data = pd.read_csv("mnist_test.csv", header=None)

train_labels = train_data.iloc[:, 0].to_numpy()
train_data = train_data.iloc[:, 1:]  # Remove column 0

test_labels = test_data.iloc[:, 0].to_numpy()
test_data = test_data.iloc[:, 1:]  # Remove column 0

# Z-Transform for train and test datasets
scaler = StandardScaler()
train_data_z = scaler.fit_transform(train_data)
test_data_z = scaler.transform(test_data)

# PCA for train and test datasets
pca = PCA(n_components=0.95)
train_data_pca = pca.fit_transform(train_data_z)
test_data_pca = pca.transform(test_data_z)

def knn_nearest_neighbors(train_data_pca, test_data_pca, k, train_labels, batch_size):
    result = []

    nn = NearestNeighbors(n_neighbors=k)
    nn.fit(train_data_pca)
    
    num_test_samples = len(test_data_pca)
    num_batches = num_test_samples // batch_size

    for i in range(num_batches):
        batch_start = i * batch_size
        batch_end = (i + 1) * batch_size

        distances, indices = nn.kneighbors(test_data_pca[batch_start:batch_end])
        neighbour_labels = train_labels[indices]

        # Perform majority voting using KNeighborsClassifier
        batch_result = np.argmax(np.apply_along_axis(np.bincount, axis=1, arr=neighbour_labels), axis=1)

        result.append(batch_result)

    result = np.concatenate(result)

    return result

def neural_network(train_data_pca, test_data_pca, train_labels, test_labels):
    # Create a neural network model
    model = Sequential()
    model.add(Dense(128, activation='relu', input_dim=train_data_pca.shape[1]))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(train_data_pca, train_labels, epochs=10, batch_size=32, verbose=0)

    # Predict the test data labels
    predictions = model.predict_classes(test_data_pca)

    return predictions

# Neural network predictions
neural_net_predictions = neural_network(train_data_pca, test_data_pca, train_labels, test_labels)
neural_net_accuracy = accuracy_score(test_labels, neural_net_predictions) * 100

results = []
accuracies = []

# Test k values from 2 to 50
k_values = range(2, 5)
batch_size = 200

for k in k_values:
    # Calculate knn with nearest neighbors
    result = knn_nearest_neighbors(train_data_pca, test_data_pca, k, train_labels, batch_size)
    results.append(result)

    # Calculate accuracy
    accuracy = np.mean(result == test_labels[:len(result)]) * 100
    accuracies.append(accuracy)
    print("KNN Accuracy for k =", k, "is", accuracy)

# Find k with the highest accuracy (KNN)
best_k_knn = k_values[np.argmax(accuracies)]
best_accuracy_knn = accuracies[np.argmax(accuracies)]
print("\nBest KNN k:", best_k_knn)
print("Best KNN accuracy:", best_accuracy_knn)

# Create csv file with real labels and predicted labels with different k-values (KNN)
results_df_knn = pd.DataFrame(results).transpose()
results_df_knn.insert(0, "Real Label", test_labels)  # Add column for real label
results_df_knn.columns = ["Real Label"] + list(k_values)  # Rename columns
results_df_knn.to_csv("knn_results_optimized2.csv", index=False)

# Create csv file with k-values and accuracies (KNN)
accuracy_df_knn = pd.DataFrame({"k": k_values, "Accuracy": accuracies})
accuracy_df_knn.to_csv("accuracy_results_optimized2.csv", index=False)

# Neural network results
neural_net_results = np.concatenate([neural_net_predictions.reshape(-1, 1), results_df_knn.iloc[:, 1:]], axis=1)
neural_net_results_df = pd.DataFrame(neural_net_results)
neural_net_results_df.insert(0, "Real Label", test_labels)  # Add column for real label
neural_net_results_df.columns = ["Real Label"] + list(k_values)  # Rename columns
neural_net_results_df.to_csv("neural_net_results.csv", index=False)

# Find k with the highest accuracy (Neural Network)
best_k_nn = k_values[np.argmax(neural_net_accuracy)]
best_accuracy_nn = np.max(neural_net_accuracy)
print("\nBest Neural Network k:", best_k_nn)
print("Best Neural Network accuracy:", best_accuracy_nn)

# Create csv file with k-values and accuracies (Neural Network)
accuracy_df_nn = pd.DataFrame({"k": k_values, "Accuracy": [neural_net_accuracy] * len(k_values)})
accuracy_df_nn.to_csv("accuracy_results_neural_net.csv", index=False)
